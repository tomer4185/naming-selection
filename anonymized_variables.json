{
  "hacksider_Deep-Live-Cam": [
    {
      "file_path": "face_analyser.py",
      "code": "import os\nimport shutil\nfrom typing import Any\nimport insightface\n\nimport cv2\nimport numpy as np\nimport modules.globals\nfrom tqdm import tqdm\nfrom modules.typing import Frame\nfrom modules.cluster_analysis import find_cluster_centroids, find_closest_centroid\nfrom modules.utilities import get_temp_directory_path, create_temp, extract_frames, clean_temp, get_temp_frame_paths\nfrom pathlib import Path\n\nFACE_ANALYSER = None\n",
      "variables": [
        "FACE_ANALYSER"
      ],
      "anonymized_code": "import os\nimport shutil\nfrom typing import Any\nimport insightface\n\nimport cv2\nimport numpy as np\nimport modules.globals\nfrom tqdm import tqdm\nfrom modules.typing import Frame\nfrom modules.cluster_analysis import find_cluster_centroids, find_closest_centroid\nfrom modules.utilities import get_temp_directory_path, create_temp, extract_frames, clean_temp, get_temp_frame_paths\nfrom pathlib import Path\n\nvar_1 = None\n",
      "lines_processed": 15,
      "total_lines": 189
    },
    {
      "file_path": "metadata.py",
      "code": "name = 'Deep-Live-Cam'\nversion = '1.8'\nedition = 'GitHub Edition'\n",
      "variables": [
        "edition",
        "name",
        "version"
      ],
      "anonymized_code": "var_3 = 'Deep-Live-Cam'\nvar_2 = '1.8'\nvar_1 = 'GitHub Edition'\n",
      "lines_processed": 3,
      "total_lines": 3
    },
    {
      "file_path": "globals.py",
      "code": "import os\nfrom typing import List, Dict, Any\n\nROOT_DIR = os.path.dirname(os.path.abspath(__file__))\nWORKFLOW_DIR = os.path.join(ROOT_DIR, \"workflow\")\n\nfile_types = [\n    (\"Image\", (\"*.png\", \"*.jpg\", \"*.jpeg\", \"*.gif\", \"*.bmp\")),\n    (\"Video\", (\"*.mp4\", \"*.mkv\")),\n]\n\nsource_target_map = []\nsimple_map = {}\n\nsource_path = None\n",
      "variables": [
        "ROOT_DIR",
        "WORKFLOW_DIR",
        "file_types",
        "simple_map",
        "source_path",
        "source_target_map"
      ],
      "anonymized_code": "import os\nfrom typing import List, Dict, Any\n\nvar_6 = os.path.dirname(os.path.abspath(__file__))\nvar_2 = os.path.join(var_6, \"workflow\")\n\nvar_4 = [\n    (\"Image\", (\"*.png\", \"*.jpg\", \"*.jpeg\", \"*.gif\", \"*.bmp\")),\n    (\"Video\", (\"*.mp4\", \"*.mkv\")),\n]\n\nvar_1 = []\nvar_5 = {}\n\nvar_3 = None\n",
      "lines_processed": 15,
      "total_lines": 43
    },
    {
      "file_path": "cluster_analysis.py",
      "code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom typing import Any\n\n\ndef find_cluster_centroids(embeddings, max_k=10) -> Any:\n    inertia = []\n    cluster_centroids = []\n    K = range(1, max_k+1)\n\n    for k in K:\n        kmeans = KMeans(n_clusters=k, random_state=0)\n        kmeans.fit(embeddings)\n        inertia.append(kmeans.inertia_)\n",
      "variables": [
        "K",
        "cluster_centroids",
        "embeddings",
        "inertia",
        "k",
        "kmeans",
        "max_k"
      ],
      "anonymized_code": "import numpy as np\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom typing import Any\n\n\ndef find_cluster_centroids(var_2, var_5=10) -> Any:\n    var_3 = []\n    var_1 = []\n    var_6 = range(1, var_5+1)\n\n    for var_7 in var_6:\n        var_4 = KMeans(n_clusters=var_7, random_state=0)\n        var_4.fit(var_2)\n        var_3.append(var_4.inertia_)\n",
      "lines_processed": 15,
      "total_lines": 32
    },
    {
      "file_path": "capturer.py",
      "code": "from typing import Any\nimport cv2\nimport modules.globals  # Import the globals to check the color correction toggle\n\n\ndef get_video_frame(video_path: str, frame_number: int = 0) -> Any:\n    capture = cv2.VideoCapture(video_path)\n\n    # Set MJPEG format to ensure correct color space handling\n    capture.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'MJPG'))\n    \n    # Only force RGB conversion if color correction is enabled\n    if modules.globals.color_correction:\n        capture.set(cv2.CAP_PROP_CONVERT_RGB, 1)\n    \n",
      "variables": [
        "capture",
        "frame_number",
        "video_path"
      ],
      "anonymized_code": "from typing import Any\nimport cv2\nimport modules.globals  # Import the globals to check the color correction toggle\n\n\ndef get_video_frame(var_2: str, var_1: int = 0) -> Any:\n    var_3 = cv2.VideoCapture(var_2)\n\n    # Set MJPEG format to ensure correct color space handling\n    var_3.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'MJPG'))\n    \n    # Only force RGB conversion if color correction is enabled\n    if modules.globals.color_correction:\n        var_3.set(cv2.CAP_PROP_CONVERT_RGB, 1)\n    \n",
      "lines_processed": 15,
      "total_lines": 32
    },
    {
      "file_path": "utilities.py",
      "code": "import glob\nimport mimetypes\nimport os\nimport platform\nimport shutil\nimport ssl\nimport subprocess\nimport urllib\nfrom pathlib import Path\nfrom typing import List, Any\nfrom tqdm import tqdm\n\nimport modules.globals\n\nTEMP_FILE = \"temp.mp4\"\n",
      "variables": [
        "TEMP_FILE"
      ],
      "anonymized_code": "import glob\nimport mimetypes\nimport os\nimport platform\nimport shutil\nimport ssl\nimport subprocess\nimport urllib\nfrom pathlib import Path\nfrom typing import List, Any\nfrom tqdm import tqdm\n\nimport modules.globals\n\nvar_1 = \"temp.mp4\"\n",
      "lines_processed": 15,
      "total_lines": 209
    },
    {
      "file_path": "typing.py",
      "code": "from typing import Any\n\nfrom insightface.app.common import Face\nimport numpy\n\nFace = Face\nFrame = numpy.ndarray[Any, Any]\n",
      "variables": [
        "Face",
        "Frame"
      ],
      "anonymized_code": "from typing import Any\n\nfrom insightface.app.common import var_2\nimport numpy\n\nvar_2 = var_2\nvar_1 = numpy.ndarray[Any, Any]\n",
      "lines_processed": 7,
      "total_lines": 7
    },
    {
      "file_path": "video_capture.py",
      "code": "import cv2\nimport numpy as np\nfrom typing import Optional, Tuple, Callable\nimport platform\nimport threading\n\n# Only import Windows-specific library if on Windows\nif platform.system() == \"Windows\":\n    from pygrabber.dshow_graph import FilterGraph\n\n\nclass VideoCapturer:\n    def __init__(self, device_index: int):\n        self.device_index = device_index\n        self.frame_callback = None\n",
      "variables": [
        "device_index",
        "self"
      ],
      "anonymized_code": "import cv2\nimport numpy as np\nfrom typing import Optional, Tuple, Callable\nimport platform\nimport threading\n\n# Only import Windows-specific library if on Windows\nif platform.system() == \"Windows\":\n    from pygrabber.dshow_graph import FilterGraph\n\n\nclass VideoCapturer:\n    def __init__(var_2, var_1: int):\n        var_2.var_1 = var_1\n        var_2.frame_callback = None\n",
      "lines_processed": 15,
      "total_lines": 94
    }
  ]
}